Polygon -10899396 true false 85 204 60 233 54 254 72 266 85 252 107 210
Polygon -7500403 true true 119 75 179 75 209 101 224 135 220 225 175 261 128 261 81 224 74 135 88 99
wheel
false
0
Circle -7500403 true true 3 3 294
Circle -16777216 true false 30 30 240
Line -7500403 true 150 285 150 15
Line -7500403 true 15 150 285 150
Circle -7500403 true true 120 120 60
Line -7500403 true 216 40 79 269
Line -7500403 true 40 84 269 221
Line -7500403 true 40 216 269 79
Line -7500403 true 84 40 221 269
x
false
0
Polygon -7500403 true true 270 75 225 30 30 225 75 270
Polygon -7500403 true true 30 75 75 30 270 225 225 270
@#$#@#$#@
NetLogo 5.0.2
@#$#@#$#@
set layout? false
setup repeat 175 [ go ]
repeat 35 [ layout ]
@#$#@#$#@
@#$#@#$#@
@#$#@#$#@
@#$#@#$#@
default
0.0
-0.2 0 0.0 1.0
0.0 1 1.0 0.0
0.2 0 0.0 1.0
link direction
true
0
Line -7500403 true 150 150 90 180
Line -7500403 true 150 150 210 180
@#$#@#$#@
0
@#$#@#$#@
?install.package
?install.packages
install.packages(sna)
install.packages("sna")
install.packages("sna", lib="/data/Rpackages/")
install.packages("RMySQL")
Sys.setenv(PKG_CPPFLAGS = "-I/usr/local/include/mysql")
Sys.setenv(PKG_LIBS = "-L/usr/local/lib -lmysqlclient")
install.packages("RMySQL", type="source")
ucscDb <- dbConnect(MySQL(),user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
library(RMySQL)
ucscDb <- dbConnect(MySQL(),user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
result
hg19 <- dbConnect(MySQL(),user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
install.packages("plyr")
install.packages("Hmisc")
library(reshape2)
head(mtcars)
library(data.table)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
# Download the file. Note: You need to unzip the file separetly if you do not have a Mac.
download.file(url, "UCI-HAR-dataset", method="curl")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
# Download the file. Note: You need to unzip the file separetly if you do not have a Mac.
download.file(url, "UCI-HAR-dataset", method="curl")
library(swirl)
wirl()
swirl()
5+7
x <- 5+7
x
y <- x-3
y
z <- c(1.1,9,3.14)
z <- 1.1,9,3.14
z <- (1.1,9,3.14)
?c
z
z+555
t <- c(z,55,z)
c(z,555,z)
z*2+100
My_sqrt <- sprt(z-1)
my_sqrt <- sprt(z-1)
my_sqrt <- (z-1)^
0.5
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4)
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+100
z*2+1000
my_div
swirl()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv,stringAsFactor=False)
mydf <- read.csv("path2csv",stringAsFactor=False)
?read.csv
mydf <- read.csv("path2csv", stringAsFactor=F)
mydf <- read.csv("path2csv", header=T, sep="," stringAsFactor=F)
mydf <- read.csv("path2csv", header=T, sep=",", stringAsFactor=F)
mydf <- read.csv("path2csv", header=T, sep=",", stringAsFactor=F)
mydf <- read.csv("path2csv", header=T, sep=",", stringAsFactors=F)
mydf <- read.csv("path2csv", stringAsFactors=F)
mydf <- read.csv(path2csv, stringAsFactors=F)
mydf <- read.csv(download.file(path2csv,"path2.csv",method="curl"), stringAsFactors=F)
mydf <- read.csv("path2.csv",stringAsFactors=F)
path2csv <- file.path(path.package('swirl'), 'Courses',
'Getting_and_Cleaning_Data',
'Manipulating_Data_with_dplyr',
'2014-07-08.csv')
# Create datasets for user. We don't advertise that we're
# doing this, but it will be necessary for students who
# quit and later resume. We are not saving the variable
# to the progress file to save on performance.
mydf <- tbl_df(read.csv(path2csv, stringsAsFactors = FALSE))
mydf <- tbl_df(read.csv(path2csv, stringsAsFactors = FALSE))
mydf <- read.csv(file.path("path2csv", "path2.csv")), stringsAsFactors = FALSE)
mydf <- read.csv(file.path("path2csv"), stringsAsFactors = FALSE)
mydf <- <- read.csv(file.path("path2csv", "path2.csv"), stringsAsFactors=FALSE)
mydf <- read.csv(file.path("path2csv", "path2.csv"), stringsAsFactors=FALSE)
get()
getwd()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(file.path("path2csv"), stringsAsFactors=FALSE)
mydf <- read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, packages, country)
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version =="3.1.1", country=="US")
?Comparison
filter(cran, r_version =="3.1.1", country=="IN")
filter(cran, r_version =="3.0.2", country=="IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, X:size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(!is.na(r_version))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, r_version,ip_id)
arrange(cran2, country, desc(r_version),ip_id)
select(cran2, ip_id, package, size)
cran3 <- select(cran2, ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size=size*1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package, drop=T)
by_package <- group_by(cran, package)
by_package
summarize(by_package,mean(size))
submit()
reset()
?n
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
skip()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack-sum, n>679)
top_counts <- filter(pack-sum, count>679)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(top_counts,desc(count))
quantile(pack_sum$unique, probs = 0.99).
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
top_unique
arrange(top_unique, desc(unique))
top_countries <- filter(pack_sum, countries > 60)
result1 <- arrange(top_countries, desc(countries), avg_bytes)
# Print the results to the console.
print(result1)
skip()
result2 <-
arrange(
filter(
summarize(
group_by(cran,
package
),
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
),
countries > 60
),
desc(countries),
avg_bytes
)
print(result2)
skip()
result3 <-
cran %>%
group_by(package) %>%
summarize(count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size)
) %>%
filter(countries > 60) %>%
arrange(desc(countries), avg_bytes)
# Print result to console
print(result3)
skip()
result5 <-
cran %>%
select(cran, ip_id,country, package, size) %>%
print(result5)
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(cran, size_mb=size/2^20)
print
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
# Your call to filter() goes here
filter(size_mb<= 0.5)
submit()
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5) %>%
# Your call to arrange() goes here
arrange(desc(size_mb))
submit()
skip()
library(dplyr)
tbl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package,mean(size))
submit()
1
submit()
submit()
manual.submit()
submit.manual()
?submit()
sessionInfo()
submit()
sessioninfo()
sessionInfo()
pack_sum
quantile(pack_sum$count, probs = 0.99
)
filter(pack_sum, count>679)
filter(pack_sum, count > 679)
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts,20)
arrange(top_counts,desc(count))
quantile(pack_sum$unique, probs = 0.99)
filter(pack_sum,unique>465)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
1
submit()
submit()
?manual
sessionInfo()
submit()
install.packages("swirl")
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
tbl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
submit
submit()
session(info)
sessionInfo(swirl)
sessionInfo
sessionInfo()
update.packages()
update.packages("swirl")
packageStatus()
print(packagesStatus())
print(packageStatus())
inst <- packageStatus()$inst
inst[inst$Status != "ok", c("Package", "Version", "Status")]
remove.packages(c("swirl")
)
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
update.packages("swirl")
remove.packages(c("swirl"),
lib = file.path("path", "to", "library"))
swirl(resume.class = "default", ...)
swirl()
install-pasckages("swirl")
install.packages("swirl")
remove.packages(c("pkg1", "pkg2"),
lib = file.path("path", "to", "/Users/isa/Library/R/3.1/library"))
remove.packages(c("swirl"),
lib = file.path("path", "to", "/Users/isa/Library/R/3.1/library"))
update.packages("swirl")
.libPaths("/Users/isa/Library/R/3.1/library")
.libPaths("~/R/x86_64-pc-linux-gnu-library/2.11")
print(.libPaths())
print(sessionInfo())
print(version)
packageVersion("swirl")
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
avg_bytes = mean(size))
submit()
submit()
library(data.frame)
x <- c(1,2,3)
x
y <- data.frame(x)
y
x <- c(1,2,3)
y <- c(4,5,6)
z <- data.frame(x,y)
z
z$log <- log10(x)
z
z$sqrt <- sqrt(x)
z
z$inv <- inv(x)
z$inv <- 1/x
z
install.packages("drDevices")
install.packages("RColorBrewer")
install.packages("colorspace")
install.packages("kernlab")
library(kernlab)
dataset(spam)
data(spam)
str(spam, 1:5)
str(spam[,1:5])
head(spam[1:5])
set.seed(3435)trainIndicator = rbinom(4601, size = 1, prob = 0.5)table(trainIndicator)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
head(spam)
trainIndicator
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
Install.packages("boot")
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
## Which predictor has minimum cross-validated error?
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
## Get predictions on the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
## Classify as `spam' for those with prob > 0.5
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
(61 + 458)/(1346 + 458 + 61 + 449)
Install.packages("stat")
Install.packages("stats")
install.packages("xtable")
setwd("/Users/isa/Documents/Courses/Johns Hopkins/Reproducible Research/Week2/RepData_PeerAssessment1")
data <- read.csv("activity.csv", colClasses = c("numeric", "factor", "numeric"))
head(data)
library(lubridate)
data$date2=as.Date(strptime(data$date, format="%Y-%m-%d" ),"%Y%m%d")
str(data)
summary(data$date2)
agg <- with(data, aggregate(data$steps, by=list(data$date2), sum))
barplot(agg$x, names.arg = agg$Group.1, col="red", main="Total number of steps per day", xlab="Days",
ylab="Frequency")
agg2 <- with(data, aggregate(data$steps, by=list(data$interval), mean, na.rm = TRUE))
plot(agg2$Group.1, agg2$x, type = "l", xlab = "Intervals", ylab = "Steps Frequency",
main="Average daily activity pattern")
names(agg2)[names(agg2) == 'Group.1'] <- 'interval'
names(agg2)[names(agg2) == 'x'] <- 'newsteps'
agg2
data2 <- merge(data, agg2, by = "interval")
tail(data2,150)
data2$steps[is.na(data2$steps)] <- data2$newsteps
data2$steps[is.na(data2$steps)] <- data2$newsteps[is.na(data2$steps)]
tail(data2)
data2$steps[is.na(data2$steps)] <- as.numeric(data2$newsteps[is.na(data2$steps)])
tail(data2)
class(data2)
class(data2$newsteps)
class(data2$steps)
data2 <- merge(data, agg2, by = "interval")
class(data2$steps)
class(data2$newsteps)
head(data2)
data2$steps[is.na(data2$steps)] <- data2$newsteps[is.na(data2$steps)]
head(data2)
tail(data2)
tail(data2,150)
Newdata <- data2[,1:4]
Newdata <- subset(data2, select = c(data2$steps,data2$interval,data2$date2))
Newdata <- subset(data2, select = c("steps","interval","date2"))
head(Newdata)
newdata <- subset(data2, select = c("steps","interval","date2"))
head(newdata)
agg3 <- with(newdata, aggregate(newdata$steps, by=list(newdata$date2), sum))
barplot(agg3$x, names.arg = agg3$Group.1, col="red", main="Total number of steps per day", xlab="Days",
ylab="Frequency")
mean(agg3[, "x"], na.rm = TRUE)
median(agg3[, "x"], na.rm = TRUE)
mean(agg3[, "x"], na.rm = F)
median(agg3[, "x"], na.rm = F)
